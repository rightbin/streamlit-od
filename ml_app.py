import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

import cv2 as cv
import tempfile


def run_ml_app():
    
    st.title('COCO DATASET & SSD')
    st.subheader('ììœ¨ì£¼í–‰ ê´€ë ¨ ë°ì´í„° ì…‹')  

    st.write('COCO datsetì€ ìˆ˜ë§ì€ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê³  ìˆìœ¼ë©° ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ ì¤‘ì—ì„œ ì €ëŠ” ssd_mobilenet_v1_coco_2017_11_17 ì„ ì´ìš©í•˜ì—¬ ë™ì˜ìƒì„ detection í•´ë³´ì•˜ìŠµë‹ˆë‹¤.')

    st.write('sdd_mobilenetì´ ê°€ì§€ê³  ìˆëŠ” classëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.')

    img = Image.open('coco.JPG')
    st.image(img)

    st.write('ì´ 99ê°œì˜ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì•ˆì—ëŠ” ì‚¬ëŒ,ìì „ê±°,ìë™ì°¨,ì˜¤í† ë°”ì´,í•¸ë“œë°±,ë„¥íƒ€ì´,ì¹«ì†” ë“±ì´ í•™ìŠµë˜ì–´ ìˆìŠµë‹ˆë‹¤.')

    st.write('streamlitì— ëª¨ë¸ë§ êµ¬í˜„ì€ EC2 (free tearì‚¬ìš©)ë¡œëŠ” êµ¬í˜„ì´ ì–´ë ¤ì› ìŠµë‹ˆë‹¤. localì—ì„œ ì§„í–‰í•œ ì˜ˆì¸¡ëª¨ë¸ì„ ìë£Œë¡œ ì²¨ë¶€í•˜ê³ ì í•©ë‹ˆë‹¤.')

    st.write('ë‹¤ìŒì˜ ë¹„ë””ì˜¤ëŠ” Pixabayì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ì•˜ìŠµë‹ˆë‹¤.')

    video_file = open('India.mp4', 'rb')
    video_bytes = video_file.read()
        
    st.video(video_bytes)

    st.write('ë‹¤ìŒì€ odject-detectionì„ í•œ í›„ì˜ ì˜ìƒì…ë‹ˆë‹¤.')

    video_result = open('output.mp4','rb')

    video2 = video_result.read()
            
    st.video(video2)

    if st.button('CLICK!'):
        video_ssd = open('SSD.mp4', 'rb')
        video3 = video_ssd.read()
        st.video(video3)

        st.text(
                """
            import tensorflow as tf
            import os
            import pathlib
            import numpy as np
            import os
            import six.moves.urllib as urllib
            import sys
            import tarfile
            import tensorflow as tf
            import zipfile
            import cv2
            import numpy as np 
            import time

            from collections import defaultdict
            from io import StringIO
            from matplotlib import pyplot as plt
            from PIL import Image
            from IPython.display import display

            from object_detection.utils import ops as utils_ops
            from object_detection.utils import label_map_util
            from object_detection.utils import visualization_utils as vis_util

            #ë²„ì ¼ í˜¸í™˜ì„ ìœ„í•œ ì½”ë“œ
            # patch tf1 into `utils.ops`
            utils_ops.tf = tf.compat.v1

            # Patch the location of gfile
            tf.gfile = tf.io.gfile

            def load_model(model_name):
                base_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'
                model_file = model_name + '.tar.gz'
                model_dir = tf.keras.utils.get_file(
                    fname=model_name, 
                    origin=base_url + model_file,
                    untar=True)

                model_dir = pathlib.Path(model_dir)/"saved_model"

                model = tf.saved_model.load(str(model_dir))

            return model

            PATH_TO_LABELS = 'C:\\Users\\JB\\Documents\\rightbin\\Tensorflow\\models\\research\\object_detection\\data\\mscoco_label_map.pbtxt'
            category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS)

            PATH_TO_TEST_IMAGES_DIR = pathlib.Path('C:\\Users\\JB\\Documents\\rightbin\\Tensorflow\\models\\research\\object_detection\\test_images')
            TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob("*.jpg")))


            # DEtection

            # http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz

            model_name = 'mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8'

            detection_model = load_model(model_name)


            detection_model.signatures['serving_default'].output_dtypes

            detection_model.signatures['serving_default'].output_shapes

            def run_inference_for_single_image(model, image):
                image = np.asarray(image)
                # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
                input_tensor = tf.convert_to_tensor(image)
                # The model expects a batch of images, so add an axis with `tf.newaxis`.
                input_tensor = input_tensor[tf.newaxis,...]

                # Run inference
                model_fn = model.signatures['serving_default']
                output_dict = model_fn(input_tensor)

                # All outputs are batches tensors.
                # Convert to numpy arrays, and take index [0] to remove the batch dimension.
                # We're only interested in the first num_detections.
                num_detections = int(output_dict.pop('num_detections'))
                output_dict = {key:value[0, :num_detections].numpy() 
                                for key,value in output_dict.items()}
                output_dict['num_detections'] = num_detections

                # detection_classes should be ints.
                output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)
                
                # Handle models with masks:
                if 'detection_masks' in output_dict:
                    output_dict['detection_masks'] = tf.convert_to_tensor(output_dict['detection_masks'], dtype=tf.float32)
                    output_dict['detection_boxes'] = tf.convert_to_tensor(output_dict['detection_boxes'], dtype=tf.float32)
                    # Reframe the the bbox mask to the image size.
                    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
                            output_dict['detection_masks'], output_dict['detection_boxes'],
                            image.shape[0], image.shape[1])  
                    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,
                                                    tf.uint8)
                    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()
                    
                return output_dict


            def show_inference(model):
                # the array based representation of the image will be used later in order to prepare the
                # result image with boxes and labels on it.
                image_np = frame
                # Actual detection.
                output_dict = run_inference_for_single_image(model, image_np)
                # Visualization of the results of a detection.
                
                vis_util.visualize_boxes_and_labels_on_image_array(
                    image_np,
                    np.array(output_dict['detection_boxes']),
                    output_dict['detection_classes'],
                    output_dict['detection_scores'],
                    category_index,
                    instance_masks=output_dict.get('detection_masks_reframed',None),
                    use_normalized_coordinates=True,
                    line_thickness=8)

                cv2.imshow("LIVE" , image_np)


                cap = cv2.VideoCapture('C:\\Users\\JB\\Documents\\rightbin\\Tensorflow\\tensorflow-object-detection\\data\\videos\\video.mp4')

                if cap.isOpened() == False :
                    print("Error opening video stream or file")

                else :

                    while(cap.isOpened()) :

                        #ì‚¬ì§„ì„ 1ì¥ì”© ê°€ì ¸ì™€ì„œ.
                        ret , frame = cap.read()

                        #ì œëŒ€ë¡œ ì‚¬ì§„ ê°€ì ¸ì™”ìœ¼ë©´, í™”ë©´ì— í‘œì‹œ!
                        if ret == True:
                            start_time = time.time()
                            show_inference(detection_model)
                            # í‚¤ë³´ë“œì—ì„œ escí‚¤ë¥¼ ëˆ„ë¥´ë©´ exití•˜ë¼ëŠ” ê²ƒ.
                            end_time = time.time()
                            print(end_time -start_time)
                            if cv2.waitKey(25) & 0xFF == 27 :
                                break 

                        else:
                            break

                # image_path = 'C:\\Users\\JB\\Documents\\rightbin\\Tensorflow\\tensorflow-object-detection\\data\\images'

            cv2.waitKey(0)
            cv2.destroyAllWindows()
            """
        )
        
    else:
        st.write(' ğŸ‘† ë²„íŠ¼ì„ í´ë¦­í•˜ì‹œë©´ êµ¬ë™ ì˜ìƒê³¼ ì½”ë“œë¥¼ í™•ì¸í•˜ì‹¤ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

    return
    